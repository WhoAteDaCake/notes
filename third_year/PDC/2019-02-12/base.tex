\documentclass{article}

\usepackage[%
    left=0.5in,%
    right=0.5in,%
    top=0.5in,%
    bottom=0.5in,%
]{geometry}%
\usepackage{minitoc}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{fixltx2e}
\usepackage{listings}
\usepackage{color}
\usepackage{hyperref}
    \hypersetup{ colorlinks = true, linkcolor = blue }
\usepackage{blindtext}
\definecolor{lightgray}{gray}{0.9}
\graphicspath{ {./} }

\newcommand{\inlinecode}[2]{\colorbox{lightgray}{\lstinline
[language=#1]$#2$}}
\newcommand{\worddef}[1]{\hyperref[sec:reference]{\textit{#1}}}

\begin{document}

\tableofcontents

\newpage

\section{Dependencies}

\begin{flushleft}
A \textbf{dependence} is an ordering relationship between two computations. For correct results the \textbf{ordering} must be observed. E.g.:
\begin{itemize}
  \item One process (or thread) waiting for data from another process (or thread)
  \item Two threads/processes reading/writing the same memory locations
\end{itemize}
\end{flushleft}

\subsection{Flow dependence}

\begin{flushleft}
A \textit{Flow} dependency, also known as a \textit{data} dependency or \textbf{true} dependency or \textit{read-after-write} (RAW), occurs when an instruction depends on the result of a previous instruction:
\[ A = 3; B = A; C = B; \]
In here last instruction is dependent on second one and second one is dependent on the first.
\end{flushleft}

\subsection{Anti dependence}
\begin{flushleft}
Write after read (WAR): a \textbf{false} dependence, only caused by \textbf{reusing the memory location}. Occurs when an instruction requires a value that is later updated. May be able to eliminate it by using \textbf{separate memory}, e.g. different variables.
\[ B = 3; A = B + 1; B = 7 \]
This prevents the instructions from being executed in parallel
\end{flushleft}

\subsection{Output	dependence}
\begin{flushleft}
Write after write (WAW): – Also a \textbf{false dependence} caused by \textbf{reusing} the memory location. May be able to eliminate it by using separate memory, e.g. different variables
\[ B = 3; A = B + 1; B = 7 \]
\end{flushleft}

\subsection{Input dependence}
\begin{flushleft}
Read after Read (RAR): \textbf{Does NOT impose} an order constraint. So usually we don’t need to worry about it at all, but it may tell us something about locality which might be useful for analysis
\end{flushleft}

\subsection{Dependencies and Parallelism}
\begin{flushleft}
Dependencies (both true and false) \textbf{limit parallelism}. E.g. adding numbers in an array : lines are true dependencies, where one function needs the result from another before it can be evaluated. These dependencies – and hence ordering constraints – are inherent to the code. \textbf{Key point}: avoid introducing dependencies that \textbf{do not matter to the computation} – they will probably limit parallelism.
\end{flushleft}

\section{Granularity}
\begin{flushleft}
The granularity of a parallel computation is how much work (how many instructions) can be done \textbf{within a single thread or process} between each interaction with another thread or process. Or equivalently how infrequent \textbf{interaction} with other threads or processes
\end{flushleft}

\subsection{Fine-grained	Parallelism}
\begin{flushleft}
Fine (small) grained parallelism has \textbf{few instructions between interactions} – interaction is \textbf{frequent}. E.g. the code generated by a parallelising compiler from a sequential program. Each thread is likely to make \textbf{frequent access to shared variables}, perhaps doing only a few instructions between each access. OK on a multi-core machine with hardware shared memory because \textbf{interaction is relatively fast}
\end{flushleft}

\subsection{Course-grained	Parallelism}
\begin{flushleft}
Coarse (large) grained parallelism \textbf{has many instructions between interactions} – interaction is \textbf{infrequent}.\\
\textbf{ E.g}. SETI@home, using home PCs connected to the Internet to analyse radio telescope data for evidence of extra-terrestrial intelligence. Each PC downloads enough \textbf{work for several hours or days}, uploaded \textbf{only when complete}. Very course-grained, because interaction (over the internet) is slow; Also makes use of the donor’s internet connection more efficient and time-limited.
\end{flushleft}

\subsection{Key point}
\begin{flushleft}
The granularity of parallelism must be appropriate for both the underlying hardware’s resources and the solution’s particular needs
 \begin{itemize}
   \item Fine-grained parallelism needs very fast interaction / communication, e.g. hardware shared memory
   \item Programs with many dependencies will tend to be more fine-grained
   \item Course granularity is good when the cost of interaction is high
 \end{itemize} 
\end{flushleft}

\subsection{Reducing Granularity}
\begin{flushleft}
\textbf{Batching} is performing work as a group
\begin{itemize}
  \item E.g. rather than sending each element of an array individually \textbf{send all of the required elements together}
  \item Or rather than a thread getting one small task at a time from a \textbf{queue get several tasks at once}
\end{itemize}
Batching makes computation more \textbf{coarse-grained} by \textbf{reducing the frequency} of interactions. But only makes sense if there are still enough chunks of work \textbf{for all the processors}, and the individual tasks \textbf{don’t have dependencies} with other tasks.
\end{flushleft}

\subsection{Increasing Granularity}
\begin{flushleft}
Over-dividing the work into more, smaller, units makes computation more \textbf{fine-grained}, since interaction is needed for (at least) every unit of work. But can make it easier to \textbf{keep all processors busy} (e.g. with its own queue of several small jobs). Especially useful if units of work are \textbf{variable or unpredictable in size} since it is hard to divide the work evenly between processors
\end{flushleft}

\section{Locality}
\begin{flushleft}
Fast programs tend to maximize the number of local memory references and minimize the number of non-local memory references.
\begin{itemize}
  \item Every non-local memory reference \textbf{requires communication}, which is an overhead 
  \item Reducing non-local references also \textbf{reduces dependences }
  \item More locality is basically always good, but it \textbf{may have a cost}, e.g. more memory or computing…
\end{itemize}
\end{flushleft}

\subsection{Increasing locality by using More Memory}
\begin{flushleft}
Using extra memory can increase parallelism by reduced false dependencies.Privatisation: rather than threads competing to access a single shared variable, \textbf{give each thread its own separate copy} that can be used independently
\end{flushleft}

\subsection{Increasing locality through Redundant Computation}
\begin{flushleft}
In a redundant computation each thread \textbf{calculates the same value locally}, instead of calculating it once in one thread and communicating the value to each thread. If each thread cannot make progress until it has the value then it \textbf{may as well spend the time calculating it for itself}. The communication is no longer required – So each thread gets the value sooner – And the dependency between threads is removed.
\end{flushleft}

\section{Performance strategies}

\subsection{Overlapping Communication and Computation}
\begin{flushleft}
Communication is often slow and hence a limiting factor. If you can identify (some) computation that is independent of the communication, then you can:
\begin{itemize}
  \item Initiate the communication
  \item Do the independent computation while you are waiting 
  \item Complete the communication (e.g. accept the data)
  \item Continue…
\end{itemize}
This overlapping of communication and computation (latency hiding) is generally useful, has few or no costs, but usually makes the \textbf{program more complex}
\end{flushleft}

\subsection{Parallelise	Overhead}
\begin{flushleft}
Parallisim in overhead: The amount of time required to coordinate parallel tasks, as opposed to do useful work. For example, in the final Pthread count3s program the results from each thread are summed in sequence because of the critical section
\begin{itemize}
  \item For a very large number of processors this could be a performance bottleneck 
  \item Switching to a tree-based summation would allow the \textbf{summation itself to be parallelised}!
\end{itemize}
\end{flushleft}

\section{Memory references}

\subsection{Memory Reference Mechanisms}
\begin{flushleft}
There are three main options for accessing non-local memory (all fit the CTA model): shared Memory, one-sided Communication, message Passing…
\end{flushleft}

\subsection{Shared Memory}
\begin{itemize}
  \item A single logically address space, accessed by all processors 
  \item All processors see consistent values when accessing memory 
  \item But different systems may provide \textbf{different levels of consistency}
\end{itemize}

\subsubsection{Sequential consistency}
\begin{itemize}
  \item As if all memory accesses by all processors were in a strict order 
  \item Like sequential execution, but least efficient
\end{itemize}

\subsubsection{Relaxed consistency}
\begin{itemize}
  \item Different processors might “see” different memory accesses under some circumstances 
  \item Performance may be better but additional \textbf{synchronization operations} may be needed in the program – E.g. Java – threads & synchronized methods
\end{itemize}

\subsection{One-sided communication}
\begin{itemize}
  \item A single logically address space, accessed by all processors 
  \item One processor can get and set values in the memory of another processor. Only that processor is involved in initiating the communication, hence “1-sided”. \textbf{No atomic get/set operation(s)} 
  \item There is no coordination between processors. A form of \textbf{relaxed consistency}.
  \item Different processors may see different values when gets/sets overlap
  \item Additional synchronization will be needed in the program for consistent results
\end{itemize}

\subsection{Message Passing}
\begin{itemize}
  \item No shared address space 
  \item To access non-local information processors \textbf{send and receive messages}
  \item Each message is both sent and received, hence “2-sided” 
  \item In the program, access to non-local information is completely different from access to local memory!
\end{itemize}

\pagebreak
\section*{Reference section} \label{sec:reference}
\begin{description}
	\item[placeholder] \hfill \\
\end{description}
\end{document}
