\documentclass{article}

\usepackage[%
    left=0.5in,%
    right=0.5in,%
    top=0.5in,%
    bottom=0.5in,%
]{geometry}%
\usepackage{minitoc}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{fixltx2e}
\usepackage{listings}
\usepackage{color}
\usepackage{hyperref}
    \hypersetup{ colorlinks = true, linkcolor = blue }
\usepackage{blindtext}
\definecolor{lightgray}{gray}{0.9}
\graphicspath{ {./} }

\newcommand{\inlinecode}[2]{\colorbox{lightgray}{\lstinline
[language=#1]$#2$}}
\newcommand{\worddef}[1]{\hyperref[sec:reference]{\textit{#1}}}

\begin{document}

\tableofcontents

\newpage

\section{Dependencies}
\begin{itemize}  
  \item A dependence is an ordering relationship \textbf{between two computations}. For correct results the ordering must be observed
  \item Examples:
  \begin{itemize}
    \item One process waiting for data from another process
    \item Two threads/processes reading/writing the same memory locations
  \end{itemize}
\end{itemize}
\begin{flushleft}
Read more \href{https://moodle.nottingham.ac.uk/pluginfile.php/4574828/mod_resource/content/2/L05-Parallel-Concepts.pdf}{here}
\end{flushleft}

\subsection{Key point}
\begin{flushleft}
avoid introducing dependencies that do not matter to the computation - they will probably limit parallelism
\end{flushleft}

\section{Granularity}
\begin{flushleft}
The granularity of a parallel computation is how much work (how many instructions) \textbf{can be done within a single thread} or process \textbf{between each interaction} with another thread or process
\end{flushleft}

\subsection{Fine-grained Parallelism}
\begin{itemize}
  \item Fine (small) grained parallelism has few instructions between interactions - \textbf{interaction is frequent}
  \item E.g. the code generated by a parallelising compiler from a sequential program
  \begin{itemize}
    \item Each thread is likely to make \textbf{frequent access to shared variables}, perhaps doing only a few instructions between each access 
    \item OK on a multi-core machine with hardware shared memory because \textbf{interaction is relatively fast}
  \end{itemize}
\end{itemize}

\subsection{Course-grained Parallelism}
\begin{itemize}
  \item Coarse (large) grained parallelism has many instructions between interactions - \textbf{interaction is infrequent}
  \item E.g. shared processing projects (SETI@home, PI digitis calculation)
  \begin{itemize}
    \item Each PC downloads enough work \textbf{for several hours or days}, uploaded only when complete
    \item Very course-grained, because \textbf{interaction (over the internet) is slow}; Also makes use of the donor’s internet connection more efficient and time-limited
  \end{itemize}
\end{itemize}

\subsection{Reducing Granularity}  
\begin{itemize}
  \item Batching is \textbf{performing work as a group}
  \item E.g. rather than sending each element of an array \textbf{individually} send all of the required elements \textbf{together} 
  \item Or rather than a thread getting one small task at a time from a queue get several tasks at once 
  \item Batching makes computation \textbf{more coarse-grained by reducing the frequency of interactions}
  \item But only makes sense if there are still\textbf{ enough chunks of work for all the processors}, and the individual tasks don’t have dependencies with other tasks
\end{itemize}

\subsection{Increasing Granularity}
\begin{itemize}
  \item Over-dividing the work into \textbf{more, smaller, units} makes computation more \textbf{fine-grained}, since interaction is needed for (at least) every unit of work 
  \item But can make it easier to keep all processors busy (e.g. with its own queue of several small jobs)
  \item Especially useful if units of work are \textbf{variable or unpredictable in size} since it is hard to divide the work evenly between processors
\end{itemize}

\subsection{Key point}
\begin{flushleft}
The granularity of parallelism must be appropriate for both the underlying hardware’s resources and the solution’s particular needs
\end{flushleft}

\section{Locality}

\subsection{Increasing locality by using More Memory}
\begin{itemize}
  \item Using extra memory can increase parallelism by reduced false dependencies (increasing locality)
  \item Privatisation: rather than threads competing to access a single shared variable, give each thread \textbf{its own separate copy} that can be used independently
  \item Padding: on some (shared memory) machines variables that are close together in memory \textbf{can be cached together}; adding extra padding can break this false dependency
\end{itemize}

\subsection{Increasing locality through Redundant Computation}
\begin{itemize}
  \item In a redundant computation \textbf{each thread calculates the same value locally} - instead of calculating it once in one thread and communicating the value to each thread
  \item If each thread cannot make progress until it has the value then it may as well spend the time calculating it for itself 
  \item The communication is no longer required
\end{itemize}

\pagebreak
\section*{Reference section} \label{sec:reference}
\begin{description}
	\item[placeholder] \hfill \\
\end{description}
\end{document}
